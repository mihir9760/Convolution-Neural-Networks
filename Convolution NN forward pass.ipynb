{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks Forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Defauling various parameters of the plots.\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution functions, including:\n",
    "    - Zero Padding\n",
    "    - Convolve window \n",
    "    - Convolution forward\n",
    "- Pooling functions, including:\n",
    "    - Pooling forward\n",
    "    - Create mask \n",
    "    - Distribute value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X, ((0,0),(pad,pad), (pad,pad), (0,0)), mode = 'constant')\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[1,1] = [[ 2.26975462 -1.45436567]\n",
      " [ 0.04575852 -0.18718385]\n",
      " [ 1.53277921  1.46935877]]\n",
      "x_pad[1,1] = [[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ecf6c42320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAACuCAYAAABUfpQYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecf6b2dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[1,1] =\", x[1,1])\n",
    "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2) #Returns the figure object and the axes object for each subplot as a sequence.\n",
    "ax[0].set_title('x')\n",
    "ax[0].imshow(x[0,:,:,0])\n",
    "ax[1].set_title('x_pad')\n",
    "ax[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    #Applying Convolution operation i.e., element wise multiplication of the image slice\n",
    "    #and the filter, and then summing over all the products.\n",
    "    s = a_slice_prev * W\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + b\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = [[[ 4.64938139]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Forward Pass\n",
    "\n",
    "\n",
    "**Formulae**:\n",
    "The formulas relating the output shape of the convolution to the input shape is:\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "$$ n_C = \\text{number of filters used in the convolution}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = np.shape(A_prev)\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = np.shape(W)\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above.\n",
    "    n_H = int(((n_H_prev + 2*pad - f) / stride) + 1)\n",
    "    n_W = int(((n_W_prev + 2*pad - f) / stride) + 1)\n",
    "    \n",
    "    # Initialize the output volume Z with zeros.\n",
    "    Z = np.zeros([m, n_H, n_W, n_C])\n",
    "    \n",
    "    # Zero padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):  # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]  # Select ith training example.\n",
    "        for h in range(n_H):  # loop over vertical axis of the output volume, rows.\n",
    "            for w in range(n_W):  # loop over horizontal axis of the output volume, columns.\n",
    "                for c in range(n_C):  # loop over channels (= #filters) of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad.\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron.\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
    "                                           \n",
    "    # Making sure the output shape is correct  \n",
    "    #(A good to have step specially when you are dealing with multi-dimensional arrays)\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = -0.44995195888\n",
      "Z[3,2,1] = [-1.02306706 -1.6233959  -1.18566576  1.26399162  2.92191922 -0.65072981\n",
      "  5.39531179  2.93454894]\n",
      "cache_conv[0][1][2][3] = [ 0.90082649  0.46566244 -1.53624369]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "A_prev = np.random.randn(10,4,4,3) #10 examples of shape 4*4*3\n",
    "W = np.random.randn(2,2,3,8) #8 filter weights of shape 2*2*3\n",
    "b = np.random.randn(1,1,1,8) #8 biases, one for each filter.\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Forward Pooling\n",
    "\n",
    "**Formulae**:\n",
    "As there's no padding, the formulas binding the output shape of the pooling to the input shape is:\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_C = n_{C_{prev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    # Finding corners\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c.\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.average(a_prev_slice)\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure the output shape is correct.\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A = [[[[ 2.26975462  1.86755799  1.46935877]]]\n",
      "\n",
      "\n",
      " [[[ 1.13940068  0.46278226  0.40234164]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[ 0.95559244  0.37051027 -0.19874578]]]\n",
      "\n",
      "\n",
      " [[[-0.57123121 -0.2293351  -0.60816277]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "qO8ng",
   "launcher_item_id": "7XDi8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
